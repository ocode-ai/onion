---
name: unit
description: |
  Gera e executa testes unitÃ¡rios automaticamente com detecÃ§Ã£o de framework.
  Use para criar testes seguindo padrÃµes do projeto e executÃ¡-los com coverage.
model: sonnet

parameters:
  - name: file-path
    description: Caminho do arquivo fonte para testar (obrigatÃ³rio)
    required: true
  - name: --generate
    description: Gera arquivo de teste se nÃ£o existir
    required: false
  - name: --run
    description: Executa os testes apÃ³s gerar/validar
    required: false
  - name: --coverage
    description: Inclui relatÃ³rio de coverage na execuÃ§Ã£o
    required: false
  - name: --watch
    description: Modo watch para re-execuÃ§Ã£o automÃ¡tica
    required: false
  - name: --framework
    description: Framework especÃ­fico (sobrescreve auto-detecÃ§Ã£o: jest|vitest|pytest|junit)
    required: false

---

# ğŸ§ª Test Unit

Gera e executa testes unitÃ¡rios automaticamente com detecÃ§Ã£o inteligente de framework, anÃ¡lise de cÃ³digo e integraÃ§Ã£o com ferramentas de coverage.

## ğŸ¯ Objetivo

Automatizar o ciclo completo de testes unitÃ¡rios:

- **Auto-detecÃ§Ã£o** de framework de teste baseado em configuraÃ§Ãµes do projeto
- **AnÃ¡lise de cÃ³digo** para identificar funÃ§Ãµes/mÃ©todos pÃºblicos testÃ¡veis
- **GeraÃ§Ã£o automÃ¡tica** de arquivos de teste seguindo padrÃµes do projeto
- **ExecuÃ§Ã£o inteligente** com suporte a coverage e watch mode
- **IntegraÃ§Ã£o** com pipeline de testes existente

## âš¡ Fluxo de ExecuÃ§Ã£o

### Passo 1: Validar Arquivo Fonte

```bash
# Verificar se arquivo existe
if [ ! -f "{{file-path}}" ]; then
  echo "âŒ ERRO: Arquivo nÃ£o encontrado: {{file-path}}"
  exit 1
fi

# Extrair informaÃ§Ãµes do arquivo
- ExtensÃ£o: .js, .ts, .tsx, .py, .java, etc.
- DiretÃ³rio base
- Nome do arquivo (sem extensÃ£o)
```

**ValidaÃ§Ãµes:**

```markdown
SE arquivo nÃ£o existe:
âŒ ERRO: Arquivo nÃ£o encontrado: {{file-path}}
ğŸ’¡ Verifique o caminho e tente novamente

SE arquivo nÃ£o Ã© cÃ³digo fonte suportado:
âš ï¸ AVISO: Tipo de arquivo pode nÃ£o ser suportado
Tipos suportados: .js, .ts, .tsx, .jsx, .py, .java, .go, .rs
```

### Passo 2: Detectar Framework de Teste

**EstratÃ©gia de DetecÃ§Ã£o (em ordem de prioridade):**

1. **Verificar configuraÃ§Ãµes:** `package.json` (Jest/Vitest), `pytest.ini` (PyTest), `pom.xml`/`build.gradle` (JUnit), `go.mod` (Go), `Cargo.toml` (Rust)
2. **Buscar arquivos de teste existentes:** `**/*.test.{js,ts}`, `**/test_*.py`, `**/*_test.go`, `**/*Test.java`
3. **Inferir por linguagem:** Jest/Vitest (JS/TS), PyTest (Python), JUnit (Java), testing (Go), cargo test (Rust)

**Output:**

```markdown
âœ… Framework: [jest|vitest|pytest|junit|go-test|rust-test]
ğŸ“ Config: [caminho]
ğŸ“¦ Package manager: [npm|pnpm|yarn|pip|maven|gradle|cargo]
```

**Se `--framework` fornecido:** Sobrescreve detecÃ§Ã£o automÃ¡tica

### Passo 3: Analisar CÃ³digo Fonte

**Objetivo:** Identificar funÃ§Ãµes/mÃ©todos pÃºblicos que precisam de testes.

#### 3.1 Ler Arquivo Fonte

```bash
read_file {{file-path}}
```

#### 3.2 Extrair FunÃ§Ãµes/MÃ©todos PÃºblicos

**PadrÃµes por linguagem:**

- **JS/TS:** `export function/const/class`, `export default`
- **Python:** `def nome_funcao` (sem `_` inicial), classes pÃºblicas
- **Java:** `public methods`, `@Test` annotations
- **Go:** `func NomeFuncao` (maiÃºscula inicial)
- **Rust:** `pub fn`, `pub struct`, `impl` pÃºblicos

#### 3.3 Identificar DependÃªncias Externas

- Imports/requires externos, APIs, arquivos/DB, dependÃªncias para mocks

**Output da AnÃ¡lise:**

```markdown
ğŸ“Š AnÃ¡lise de CÃ³digo:
âˆŸ FunÃ§Ãµes pÃºblicas encontradas: [N]
âˆŸ Classes encontradas: [N]
âˆŸ DependÃªncias externas: [lista]
âˆŸ Complexidade estimada: [baixa|mÃ©dia|alta]
```

### Passo 4: Verificar Arquivo de Teste Existente

**PadrÃµes de nomenclatura:**

- **Jest/Vitest:** `{{file}}.test.{js,ts,tsx}`
- **PyTest:** `test_{{file}}.py` ou `tests/test_{{file}}.py`
- **JUnit:** `{{Class}}Test.java` em `src/test/`
- **Go:** `{{file}}_test.go`
- **Rust:** `#[cfg(test)]` no mesmo arquivo

**DecisÃ£o:**

```markdown
SE arquivo existe:
âœ… Encontrado: [caminho]
SE --generate: âš ï¸ Pula geraÃ§Ã£o, continua execuÃ§Ã£o
SENÃƒO: Continua execuÃ§Ã£o

SE nÃ£o existe:
SE --generate: â†’ Gerar (Passo 5)
SENÃƒO: âŒ ERRO: Use --generate para criar
```

### Passo 5: Gerar Arquivo de Teste (SE --generate)

**EstratÃ©gia:**

1. **Ler padrÃµes existentes:** Buscar `**/*.test.{js,ts}`, `**/test_*.py` para extrair estrutura, imports, nomenclatura
2. **Gerar testes base:** PadrÃ£o AAA (Arrange, Act, Assert) para cada funÃ§Ã£o pÃºblica:
   - Happy path: entrada vÃ¡lida â†’ saÃ­da esperada
   - Edge cases: null, vazios, limites
   - Error handling: entradas invÃ¡lidas â†’ exceÃ§Ãµes
3. **Configurar mocks:** Para dependÃªncias externas (Jest: `jest.mock()`, Vitest: `vi.mock()`)
4. **Criar arquivo:** `write {{test-file-path}}`

**Exemplo estrutura (Jest/Vitest):**

```typescript
describe('nomeFuncao', () => {
  test('should return expected result with valid input', () => {
    const result = nomeFuncao('valid input');
    expect(result).toBe('expected output');
  });
  test('should handle edge case', () => {
    expect(() => nomeFuncao(null)).toThrow();
  });
});
```

**ValidaÃ§Ã£o:** âœ… Arquivo gerado: {{test-file-path}}, [N] testes (happy path: X, edge: Y, errors: Z)

### Passo 6: Executar Testes (SE --run)

**Comandos por framework:**

- **Jest:** `npx jest {{test-file}} [--coverage] [--watch]` ou `pnpm jest`
- **Vitest:** `npx vitest [run] {{test-file}} [--coverage]` ou `pnpm vitest`
- **PyTest:** `pytest {{test-file}} [--cov={{dir}} --cov-report=html]` ou `ptw` (watch)
- **JUnit:** `mvn test -Dtest={{Class}}` ou `./gradlew test --tests {{Class}}`
- **Go:** `go test ./{{pkg}} [-v] [-cover]`
- **Rust:** `cargo test {{name}}`

**Construir comando:** Base + `--coverage` (se flag) + `--watch` (se flag) + execuÃ§Ã£o Ãºnica (se nÃ£o watch)

**Executar:** `run_terminal_cmd [comando]` e capturar: resultados (pass/fail), coverage (se aplicÃ¡vel), erros, tempo

### Passo 7: Apresentar Resultados

## ğŸ“¤ Output Esperado

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… TESTES UNITÃRIOS - {{file-path}}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” DetecÃ§Ã£o:
âˆŸ Framework: [jest|vitest|pytest|junit|go-test|rust-test]
âˆŸ Config: [caminho do arquivo de config]
âˆŸ Package manager: [npm|pnpm|yarn|pip|maven|gradle|cargo]

ğŸ“Š AnÃ¡lise de CÃ³digo:
âˆŸ Arquivo fonte: {{file-path}}
âˆŸ FunÃ§Ãµes pÃºblicas: [N]
âˆŸ Classes: [N]
âˆŸ DependÃªncias externas: [lista]
âˆŸ Complexidade: [baixa|mÃ©dia|alta]

ğŸ“ Arquivo de Teste:
âˆŸ Status: [âœ… Existente | âœ… Gerado | âŒ NÃ£o encontrado]
âˆŸ Caminho: {{test-file-path}}
âˆŸ Testes: [N] casos de teste
  â”œâ”€ Happy path: [N]
  â”œâ”€ Edge cases: [N]
  â””â”€ Error handling: [N]

ğŸ§ª ExecuÃ§Ã£o:
âˆŸ Comando: [comando executado]
âˆŸ Status: [âœ… Passou | âŒ Falhou | âš ï¸ Parcial]
âˆŸ Testes executados: [X/Y] passaram
âˆŸ Tempo: [X]s

ğŸ“ˆ Coverage (se --coverage):
âˆŸ Statements: [X]%
âˆŸ Branches: [X]%
âˆŸ Functions: [X]%
âˆŸ Lines: [X]%
âˆŸ Arquivo: [caminho do relatÃ³rio]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ PrÃ³ximos Passos:
1. Revisar testes gerados e adicionar casos especÃ­ficos
2. Executar novamente: /test/unit {{file-path}} --run
3. Integrar no pipeline: /validate/test-strategy/create
4. Code review: /git/code-review

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## ğŸ“‹ Exemplos de Uso

**1. Gerar e executar com coverage:**

```bash
/test/unit src/utils/validation.js --generate --run --coverage
```

â†’ Detecta framework, analisa cÃ³digo, gera `validation.test.js`, executa com coverage

**2. Apenas gerar teste:**

```bash
/test/unit app/models/user.py --generate --framework pytest
```

â†’ ForÃ§a PyTest, gera `test_user.py`, nÃ£o executa

**3. Executar com watch:**

```bash
/test/unit components/Button.tsx --run --watch
```

â†’ Detecta framework, executa `Button.test.tsx` em modo watch

**4. Executar teste existente:**

```bash
/test/unit src/services/api.ts --run --coverage
```

â†’ Encontra `api.test.ts`, executa com coverage, nÃ£o gera novo arquivo

## âš™ï¸ ParÃ¢metros Detalhados

| ParÃ¢metro     | Tipo   | ObrigatÃ³rio | DescriÃ§Ã£o                                        |
| ------------- | ------ | ----------- | ------------------------------------------------ |
| `file-path`   | string | âœ…          | Caminho do arquivo fonte para testar             |
| `--generate`  | flag   | âŒ          | Gera arquivo de teste se nÃ£o existir             |
| `--run`       | flag   | âŒ          | Executa os testes apÃ³s gerar/validar             |
| `--coverage`  | flag   | âŒ          | Inclui relatÃ³rio de coverage                     |
| `--watch`     | flag   | âŒ          | Modo watch para re-execuÃ§Ã£o automÃ¡tica           |
| `--framework` | string | âŒ          | Framework especÃ­fico (sobrescreve auto-detecÃ§Ã£o) |

## ğŸ”— Comandos Relacionados

- `/test/integration` - Testes de integraÃ§Ã£o (Grey-box)
- `/test/e2e` - Testes end-to-end (Black-box)
- `/validate/test-strategy/create` - Criar estratÃ©gia completa de testes
- `/engineer/work` - Continuar desenvolvimento com testes
- `/git/code-review` - Revisar cÃ³digo incluindo testes

## âš ï¸ ValidaÃ§Ãµes e Regras

### ValidaÃ§Ãµes ObrigatÃ³rias

1. **Arquivo fonte deve existir:**

   ```markdown
   SE arquivo nÃ£o encontrado:
   âŒ ERRO: Arquivo nÃ£o encontrado: {{file-path}}
   ```

2. **Framework deve ser detectÃ¡vel ou fornecido:**

   ```markdown
   SE nenhum framework detectado E --framework nÃ£o fornecido:
   âŒ ERRO: NÃ£o foi possÃ­vel detectar framework de teste
   ğŸ’¡ Instale um framework ou use --framework [nome]
   ```

3. **Arquivo de teste deve existir para execuÃ§Ã£o:**
   ```markdown
   SE --run fornecido E arquivo de teste nÃ£o existe E --generate nÃ£o fornecido:
   âŒ ERRO: Arquivo de teste nÃ£o encontrado
   ğŸ’¡ Use --generate para criar automaticamente
   ```

### Regras de NegÃ³cio

1. **Auto-detecÃ§Ã£o tem prioridade** sobre --framework, exceto se --framework fornecido
2. **GeraÃ§Ã£o segue padrÃµes** do projeto (analisa testes existentes)
3. **Coverage requer** framework com suporte (Jest, Vitest, PyTest)
4. **Watch mode** mantÃ©m processo rodando atÃ© interrupÃ§Ã£o
5. **Testes gerados** cobrem happy path, edge cases e error handling bÃ¡sicos

## ğŸ”§ Suporte por Linguagem

| Linguagem | Frameworks          | Coverage | Watch |
| --------- | ------------------- | -------- | ----- |
| JS/TS     | Jest, Vitest, Mocha | âœ…       | âœ…    |
| Python    | PyTest, unittest    | âœ…       | âš ï¸    |
| Java      | JUnit 5/4           | âœ…       | âŒ    |
| Go        | testing (built-in)  | âœ…       | âš ï¸    |
| Rust      | cargo test          | âš ï¸       | âŒ    |

## ğŸ“š ReferÃªncias

- **Agente de Testes:** @test-engineer
- **Framework de Testes:** `docs/knowbase/frameworks/framework_testes.md`
- **PadrÃµes de Teste:** `${CLAUDE_PLUGIN_ROOT}/agents/testing/test-engineer.md`

## âš ï¸ Notas Importantes

- **Auto-detecÃ§Ã£o inteligente:** Analisa configuraÃ§Ãµes e padrÃµes do projeto
- **GeraÃ§Ã£o conservadora:** Cria testes bÃ¡sicos, desenvolvedor deve expandir
- **IntegraÃ§Ã£o com pipeline:** Testes gerados seguem padrÃµes do projeto
- **Coverage opcional:** Requer configuraÃ§Ã£o prÃ©via do framework
- **Watch mode:** MantÃ©m processo ativo, use Ctrl+C para parar

---

**VersÃ£o:** 3.0.0  
**Ãšltima atualizaÃ§Ã£o:** 2025-11-24  
**Mantido por:** Sistema Onion
