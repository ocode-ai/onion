---
name: test-strategy-analyze
description: |
  Analisa estratÃ©gias de teste existentes e sugere melhorias baseadas no Framework de Testes.
  Use para auditar conformidade, identificar gaps e otimizar estratÃ©gias de teste com base no framework.
model: sonnet

parameters:
  - name: feature-id
    description: ID da feature/epic no task manager (ex: PROJ-123, CU-456)
    required: true
  - name: task-manager
    description: Provedor do task manager (jira|clickup|asana). Se nÃ£o fornecido, serÃ¡ inferido automaticamente do .env ou formato do feature-id
    required: false
  - name: deep-scan
    description: AnÃ¡lise profunda incluindo cÃ³digo e cobertura
    required: false
  - name: auto-fix
    description: Aplica correÃ§Ãµes automÃ¡ticas quando possÃ­vel
    required: false
  - name: export-report
    description: Gera relatÃ³rio detalhado em arquivo
    required: false

---

# ğŸ” AnÃ¡lise de EstratÃ©gia de Teste

Analisa estratÃ©gias de teste existentes e sugere melhorias baseadas no Framework de Testes (`docs/knowbase/frameworks/framework_testes.md`), identificando gaps de conformidade e oportunidades de otimizaÃ§Ã£o.

## ğŸ¯ Objetivo

Auditar e melhorar estratÃ©gias de teste existentes atravÃ©s de:

- AnÃ¡lise de conformidade com o Framework de Testes
- IdentificaÃ§Ã£o de gaps de cobertura e qualidade
- SugestÃµes priorizadas de melhorias
- CorreÃ§Ãµes automÃ¡ticas quando aplicÃ¡vel
- RelatÃ³rios detalhados e acionÃ¡veis

## âš¡ Fluxo de ExecuÃ§Ã£o

### Passo 1: Carregar Framework de Testes (OBRIGATÃ“RIO)

**CRÃTICO:** Sempre ler o framework antes de qualquer anÃ¡lise:

```bash
# Ler framework completo
read_file docs/knowbase/frameworks/framework_testes.md
```

**Extrair e armazenar em memÃ³ria:**

- SeÃ§Ã£o "QA Story Points - Sistema de Estimativa" (linhas ~217-330)
- SeÃ§Ã£o "DiferenÃ§as entre White-box vs Black-box vs Grey-box" (linhas ~111-165)
- SeÃ§Ã£o "TÃ©cnicas EspecÃ­ficas por Tipo" (linhas ~464-594)
- SeÃ§Ã£o "MÃ©tricas de Qualidade" (linhas ~598-649)
- SeÃ§Ã£o "Template Universal de Caso de Teste" (linhas ~171-213)
- SeÃ§Ã£o "PadrÃµes de ColaboraÃ§Ã£o" (linhas ~855-928)

**Validar leitura:**

```markdown
SE arquivo nÃ£o encontrado:
âŒ ERRO: Framework de testes nÃ£o encontrado em docs/knowbase/frameworks/framework_testes.md
ğŸ’¡ Verifique se o arquivo existe e tente novamente
```

### Passo 2: Detectar e Configurar Task Manager

**CRÃTICO:** Detectar provedor automaticamente do `.env` primeiro, depois usar fallback:

```bash
# EXECUTAR PRIMEIRO: Ler .env para detectar provedor
read_file .env
```

**LÃ³gica de detecÃ§Ã£o (prioridade):**

```markdown
**1. SE {{task-manager}} fornecido explicitamente:**
usar {{task-manager}} diretamente
validar que estÃ¡ em: jira|clickup|asana

**2. SENÃƒO, tentar detectar do .env:**
Extrair TASK_MANAGER_PROVIDER do .env
SE encontrado e vÃ¡lido (clickup|asana|linear):
task-manager = TASK_MANAGER_PROVIDER
SE linear: converter para jira (compatibilidade)

**3. SENÃƒO, tentar detectar pelo formato do feature-id:**
SE feature-id comeÃ§a com "CU-" ou "cu-":
task-manager = "clickup"
SE feature-id comeÃ§a com "PROJ-", "JIRA-", "JIRA-" ou padrÃ£o numÃ©rico:
task-manager = "jira"
SE feature-id comeÃ§a com "ASANA-" ou padrÃ£o especÃ­fico:
task-manager = "asana"

**4. SENÃƒO (nenhum mÃ©todo funcionou):**
âŒ ERRO: NÃ£o foi possÃ­vel detectar task manager
ğŸ’¡ Configure TASK_MANAGER_PROVIDER no .env ou forneÃ§a --task-manager
```

**ValidaÃ§Ãµes:**

```markdown
- feature-id nÃ£o pode estar vazio
- task-manager detectado deve ser vÃ¡lido: jira|clickup|asana
- SE task-manager nÃ£o detectado: abortar com erro claro
```

### Passo 3: Validar e Normalizar ParÃ¢metros

```markdown
**ParÃ¢metros normalizados:**

- feature-id: {{feature-id}} âœ… obrigatÃ³rio
- task-manager: [detectado do .env ou formato] âœ… detectado automaticamente
- deep-scan: {{deep-scan}} ou false
- auto-fix: {{auto-fix}} ou false
- export-report: {{export-report}} ou false
```

### Passo 4: Coletar Dados do Task Manager

**CRÃTICO:** Seguir padrÃ£o de `/product/task` para integraÃ§Ã£o (`.env` jÃ¡ foi lido no Passo 2):

**Buscar dados completos da feature/epic:**

**Para ClickUp:**

```markdown
1. Buscar epic principal usando feature-id
   - Usar mcp_ClickUp_clickup_get_task ou mcp_ClickUp_clickup_search_tasks
   - Extrair: nome, descriÃ§Ã£o, status, labels, custom fields (QA Story Points)
2. Buscar todas subtasks relacionadas
   - Usar mcp_ClickUp_clickup_get_subtasks ou filtrar por parent
   - Para cada subtask: nome, status, pontos, labels, comentÃ¡rios
3. Buscar histÃ³rico e mÃ©tricas
   - ComentÃ¡rios com timestamps
   - MudanÃ§as de status
   - Time tracking (se disponÃ­vel)
```

**Para Jira:**

```markdown
1. Buscar epic/issue principal
   - Usar API Jira ou MCP equivalente
   - Extrair: summary, description, status, labels, story points
2. Buscar linked issues (subtasks)
   - Issues vinculadas ao epic
   - Para cada: summary, status, story points, comments
3. Buscar histÃ³rico
   - Changelog para mudanÃ§as de status
   - Comments com timestamps
   - Worklog (tempo gasto)
```

**Para Asana:**

```markdown
1. Buscar task principal
   - Usar mcp_asana_asana_get_task
   - Extrair: name, notes, status, custom fields
2. Buscar subtasks
   - Usar mcp_asana_asana_get_subtasks
   - Para cada: name, status, custom fields, comments
3. Buscar histÃ³rico
   - Stories (histÃ³rico de mudanÃ§as)
   - Comments com timestamps
```

**Dados a coletar:**

- Epic/feature principal: nome, descriÃ§Ã£o, status, labels/tags
- QA Story Points atribuÃ­dos vs estimados
- Todas subtasks relacionadas (White-box, Grey-box, Black-box)
- Status atual de cada task
- Acceptance criteria definidos
- HistÃ³rico de updates e comentÃ¡rios
- Tempo gasto vs tempo estimado (se disponÃ­vel)
- Labels e tags de categorizaÃ§Ã£o

### Passo 5: Coletar Dados do CÃ³digo (se --deep-scan)

**SE deep-scan = true:**

```bash
# Buscar estrutura de testes no cÃ³digo
glob_file_search "**/*test*.{js,ts,jsx,tsx,py,spec.js,spec.ts}"
glob_file_search "**/*.test.{js,ts,jsx,tsx,py}"
glob_file_search "**/__tests__/**/*"
glob_file_search "**/tests/**/*"
glob_file_search "**/spec/**/*"

# Buscar arquivos de configuraÃ§Ã£o
glob_file_search "**/jest.config.*"
glob_file_search "**/pytest.ini"
glob_file_search "**/.nycrc*"
glob_file_search "**/coverage/**/*"

# Buscar CI/CD configs
glob_file_search "**/.github/workflows/*test*.yml"
glob_file_search "**/.gitlab-ci.yml"
glob_file_search "**/azure-pipelines.yml"
```

**Analisar estrutura de testes:**

```markdown
1. Identificar tipos de teste presentes:
   - Unit tests (White-box)
   - Integration tests (Grey-box)
   - E2E tests (Black-box)
2. Contar arquivos por tipo
3. Verificar padrÃµes de nomenclatura
4. Identificar estrutura de diretÃ³rios
```

**Buscar mÃ©tricas de cobertura:**

```markdown
1. Ler coverage reports se existirem:
   - coverage/lcov-report/index.html
   - coverage/coverage-summary.json
   - .nyc_output/coverage.json
2. Extrair mÃ©tricas:
   - Line coverage
   - Branch coverage
   - Function coverage
   - Statement coverage
```

**Analisar configuraÃ§Ãµes de CI/CD:**

```markdown
1. Verificar pipelines de teste
2. Identificar quality gates
3. Verificar thresholds de cobertura
4. Analisar execuÃ§Ã£o de testes
```

**Buscar logs de execuÃ§Ã£o:**

```markdown
1. Verificar histÃ³rico de falhas recentes
2. Identificar testes flaky
3. Analisar tempo de execuÃ§Ã£o
4. Verificar trends de qualidade
```

### Passo 6: Analisar Conformidade com Framework

**5.1. ValidaÃ§Ã£o de QA Story Points**

```markdown
**Verificar cada task:**

1. Extrair QA points atribuÃ­dos (custom field ou label)
2. Calcular QA points esperados usando fÃ³rmula do framework:
   - Complexidade Base (simples: 1-2, mÃ©dio: 3-5, complexo: 5-8, Ã©pico: 8-13)
   - Ajuste por Risco (baixo: +0-1, mÃ©dio: +1-2, alto: +2-3, crÃ­tico: +3-5)
   - Tipo de Teste (bÃ¡sico: +1, padrÃ£o: +2-3, extensivo: +4-6)
3. Comparar atribuÃ­do vs calculado
4. Identificar discrepÃ¢ncias >20% como problema

**DistribuiÃ§Ã£o por perspectiva:**

- Verificar se pontos estÃ£o distribuÃ­dos entre White/Grey/Black-box
- Validar proporÃ§Ãµes sugeridas pelo framework:
  - Simples/MÃ©dio: White 30%, Grey 30%, Black 40%
  - Complexo/Ã‰pico: White 25%, Grey 35%, Black 40%
```

**5.2. AnÃ¡lise Multi-Perspectiva**

```markdown
**Verificar cobertura das 3 perspectivas:**

1. White-box (Developer Testing):
   - Existem tasks/subtasks de unit testing?
   - TÃ©cnicas mencionadas: Code Coverage, Mutation Testing?
   - MÃ©tricas definidas: >80% coverage, >70% mutation score?
   - Ferramentas: Jest, PyTest, JUnit mencionadas?

2. Grey-box (Cross-Dev Testing):
   - Existem tasks de integration testing?
   - TÃ©cnicas: API Contract Testing, Fuzzing?
   - MÃ©tricas: >95% integration pass rate, 100% API contract coverage?
   - Foco em contratos e fronteiras?

3. Black-box (QA Testing):
   - Existem tasks de system/acceptance testing?
   - TÃ©cnicas: PartiÃ§Ã£o de EquivalÃªncia, AnÃ¡lise de Valor Limite?
   - MÃ©tricas: 100% user story coverage, >85% bug detection rate?
   - Foco em jornada do usuÃ¡rio?

**Calcular score de cobertura:**

- 100% = todas 3 perspectivas presentes e bem definidas
- 67% = 2 perspectivas presentes
- 33% = 1 perspectiva presente
- 0% = nenhuma perspectiva identificada
```

**5.3. Conformidade com Templates**

```markdown
**Verificar se tasks seguem template universal:**

1. Acceptance criteria completos?
   - Objetivo claro
   - PrÃ©-condiÃ§Ãµes definidas
   - Dados de teste especificados
   - Passos de execuÃ§Ã£o
   - Resultado esperado
   - CritÃ©rios de sucesso

2. Template de caso de teste presente?
   - Tipo (Unit/Integration/System/Acceptance)
   - Perspectiva (White/Grey/Black-box)
   - Prioridade e complexidade
   - QA Story Points
   - Tags apropriadas

3. MÃ©tricas de sucesso definidas?
   - Thresholds claros
   - KPIs mensurÃ¡veis
   - CritÃ©rios de aceitaÃ§Ã£o
```

**5.4. PadrÃµes de ColaboraÃ§Ã£o**

```markdown
**Verificar evidÃªncia de colaboraÃ§Ã£o:**

1. Three Amigos sessions:
   - ComentÃ¡rios indicando discussÃ£o PO+Dev+QA?
   - HistÃ³rico mostra refinement sessions?
   - Acceptance criteria refinados colaborativamente?

2. Pair Testing:
   - ComentÃ¡rios mencionam pair testing?
   - Tasks atribuÃ­das a mÃºltiplos owners?
   - EvidÃªncia de cross-review?

3. Handoff Protocols:
   - ComentÃ¡rios de handoff Devâ†’QA?
   - DocumentaÃ§Ã£o de "how to test"?
   - EvidÃªncia de validaÃ§Ã£o de estimativas?
```

### Passo 7: Detectar Gaps e Problemas

**6.1. Identificar Gaps de Cobertura**

```markdown
**Perspectivas faltantes:**

- SE apenas White-box presente: falta Grey e Black-box
- SE apenas Black-box presente: falta White e Grey-box
- SE apenas Grey-box presente: falta White e Black-box
- SE nenhuma perspectiva clara: gap crÃ­tico

**TÃ©cnicas faltantes:**

- White-box sem Mutation Testing: gap mÃ©dio
- Grey-box sem API Contract Testing: gap alto
- Black-box sem Exploratory Testing: gap mÃ©dio
- Sem automaÃ§Ã£o quando deveria ter: gap alto
```

**6.2. Identificar Estimativas Incorretas**

```markdown
**Comparar estimado vs real (se dados disponÃ­veis):**

- SE tempo gasto > 150% do estimado: sobre-estimativa ou complexidade subestimada
- SE tempo gasto < 50% do estimado: sub-estimativa ou complexidade superestimada
- SE QA points atribuÃ­dos â‰  calculados pelo framework: recalcular necessÃ¡rio

**Identificar padrÃµes:**

- Tasks consistentemente subestimadas: problema de processo
- Tasks consistentemente superestimadas: problema de processo
- VariaÃ§Ã£o alta: falta de padronizaÃ§Ã£o
```

**6.3. Identificar MÃ©tricas Fora do Threshold**

```markdown
**Comparar mÃ©tricas atuais vs thresholds do framework:**

1. Code Coverage:
   - SE < 80%: CRITICAL gap
   - SE 80-85%: MEDIUM gap (prÃ³ximo do limite)
   - SE > 85%: OK

2. Integration Pass Rate:
   - SE < 95%: HIGH gap
   - SE 95-98%: MEDIUM gap
   - SE > 98%: OK

3. Mutation Score:
   - SE < 70%: HIGH gap
   - SE 70-75%: MEDIUM gap
   - SE > 75%: OK

4. Bug Detection Rate:
   - SE < 85%: HIGH gap
   - SE 85-90%: MEDIUM gap
   - SE > 90%: OK

5. QA Estimation Accuracy:
   - SE < 80%: HIGH gap
   - SE 80-85%: MEDIUM gap
   - SE > 85%: OK
```

**6.4. Identificar TÃ©cnicas Inadequadas**

```markdown
**Verificar alinhamento tÃ©cnica-tipo:**

- White-box usando tÃ©cnicas de Black-box: inadequado
- Black-box usando tÃ©cnicas de White-box: inadequado
- TÃ©cnicas nÃ£o mencionadas no framework: verificar relevÃ¢ncia
- TÃ©cnicas obsoletas: sugerir atualizaÃ§Ã£o
```

**6.5. Identificar Falta de AutomaÃ§Ã£o**

```markdown
**Verificar tasks que deveriam estar automatizadas:**

- Testes de regressÃ£o manuais: deveriam ser automÃ¡ticos
- Testes repetitivos manuais: candidatos a automaÃ§Ã£o
- Testes de smoke sem automaÃ§Ã£o: gap mÃ©dio
- E2E crÃ­ticos sem automaÃ§Ã£o: gap alto
```

**6.6. Identificar Debt TÃ©cnico**

```markdown
**Problemas de qualidade:**

- Testes flaky mencionados em comentÃ¡rios: debt tÃ©cnico
- Tempo de execuÃ§Ã£o muito alto: otimizaÃ§Ã£o necessÃ¡ria
- Cobertura baixa em Ã¡reas crÃ­ticas: risco alto
- Testes mal estruturados: refatoraÃ§Ã£o necessÃ¡ria
```

### Passo 8: Calcular Impacto dos Gaps

**7.1. Risco de Bugs em ProduÃ§Ã£o**

```markdown
**Calcular risco baseado em gaps:**

- CRITICAL gaps: risco alto de bugs crÃ­ticos
- HIGH gaps: risco mÃ©dio-alto de bugs
- MEDIUM gaps: risco mÃ©dio
- LOW gaps: risco baixo

**Fatores de risco:**

- Cobertura insuficiente + Ã¡rea crÃ­tica = risco muito alto
- Falta de perspectiva + complexidade alta = risco alto
- MÃ©tricas abaixo do threshold = risco mÃ©dio-alto
```

**7.2. EficiÃªncia Perdida**

```markdown
**Calcular impacto em tempo/custo:**

- Estimativas incorretas: tempo perdido em replanejamento
- Falta de automaÃ§Ã£o: tempo manual repetitivo
- Testes flaky: tempo perdido em debugging
- Debt tÃ©cnico: tempo futuro de refatoraÃ§Ã£o

**Estimativas:**

- Cada gap CRITICAL: ~8-16 horas de impacto
- Cada gap HIGH: ~4-8 horas de impacto
- Cada gap MEDIUM: ~2-4 horas de impacto
- Cada gap LOW: ~1-2 horas de impacto
```

**7.3. Qualidade Comprometida**

```markdown
**Score de qualidade:**

- Base: 100 pontos
- CRITICAL gap: -20 pontos cada
- HIGH gap: -10 pontos cada
- MEDIUM gap: -5 pontos cada
- LOW gap: -2 pontos cada

**InterpretaÃ§Ã£o:**

- 90-100: Excelente
- 75-89: Bom (melhorias recomendadas)
- 60-74: Regular (melhorias necessÃ¡rias)
- <60: CrÃ­tico (aÃ§Ã£o imediata)
```

**7.4. Velocity do Time Afetada**

```markdown
**Impacto na velocidade:**

- Estimativas incorretas: afeta planejamento
- Testes flaky: reduz confianÃ§a e velocidade
- Falta de automaÃ§Ã£o: reduz capacidade de entrega
- Debt tÃ©cnico: acumula e reduz velocidade ao longo do tempo
```

### Passo 9: Gerar SugestÃµes de Melhoria

**8.1. Categorizar por Severidade**

```markdown
**CRITICAL - Fixes que impactam qualidade diretamente:**

- Cobertura abaixo de threshold crÃ­tico
- Perspectivas crÃ­ticas faltando
- MÃ©tricas crÃ­ticas nÃ£o atingidas
- Risco alto de bugs em produÃ§Ã£o

**HIGH - OtimizaÃ§Ãµes que melhoram eficiÃªncia significativamente:**

- Estimativas incorretas afetando planejamento
- Falta de automaÃ§Ã£o em Ã¡reas crÃ­ticas
- TÃ©cnicas inadequadas
- MÃ©tricas importantes abaixo do threshold

**MEDIUM - Ajustes para conformidade com framework:**

- Templates nÃ£o seguindo padrÃ£o
- Labels/tags faltantes
- TÃ©cnicas nÃ£o otimais
- MÃ©tricas prÃ³ximas do threshold

**LOW - Tweaks para otimizaÃ§Ã£o geral:**

- Melhorias de documentaÃ§Ã£o
- OtimizaÃ§Ãµes menores
- Ajustes de processo
- Refinamentos de mÃ©tricas
```

**8.2. Tipos de SugestÃµes**

**Redistribuir QA Points:**

```markdown
SugestÃ£o: Recalcular QA Story Points usando fÃ³rmula do framework

- Task: [ID] - Atual: [X] pontos, Esperado: [Y] pontos
- AÃ§Ã£o: Atualizar custom field ou label
- Impacto: Melhor estimativa e planejamento
- EsforÃ§o: 15 minutos por task
```

**Adicionar Perspectivas:**

```markdown
SugestÃ£o: Implementar perspectiva [White/Grey/Black-box] faltante

- Gap identificado: [descriÃ§Ã£o]
- AÃ§Ã£o: Criar subtasks para perspectiva faltante
- Impacto: Cobertura completa multi-perspectiva
- EsforÃ§o: [X] horas baseado em complexidade
```

**Upgrade TÃ©cnicas:**

```markdown
SugestÃ£o: Migrar de [tÃ©cnica atual] para [tÃ©cnica recomendada]

- RazÃ£o: [tÃ©cnica atual] nÃ£o Ã© adequada para [tipo de teste]
- AÃ§Ã£o: Refatorar testes para usar [tÃ©cnica recomendada]
- Impacto: Maior eficÃ¡cia e alinhamento com framework
- EsforÃ§o: [X] horas
```

**Automatizar Tasks:**

```markdown
SugestÃ£o: Automatizar testes manuais de [Ã¡rea]

- Tasks afetadas: [lista de IDs]
- AÃ§Ã£o: Criar suite de testes automatizados
- Impacto: ReduÃ§Ã£o de tempo manual, maior confiabilidade
- EsforÃ§o: [X] horas (ROI: [Y] horas economizadas)
```

**Fix MÃ©tricas:**

```markdown
SugestÃ£o: Atingir threshold de [mÃ©trica]

- MÃ©trica atual: [X]%
- Threshold: [Y]%
- Gap: [Z]%
- AÃ§Ã£o: [aÃ§Ãµes especÃ­ficas para atingir threshold]
- Impacto: Conformidade com framework, maior qualidade
- EsforÃ§o: [X] horas
```

**Restructure Tasks:**

```markdown
SugestÃ£o: Reorganizar Ã©pico/subtasks para melhor flow

- Problema: [estrutura atual problemÃ¡tica]
- AÃ§Ã£o: [nova estrutura proposta]
- Impacto: Melhor organizaÃ§Ã£o e rastreabilidade
- EsforÃ§o: [X] horas
```

**8.3. Estimar EsforÃ§o**

```markdown
**Para cada sugestÃ£o, estimar:**

- Tempo necessÃ¡rio (horas)
- DependÃªncias
- Prioridade relativa
- ROI esperado

**FÃ³rmula de priorizaÃ§Ã£o:**
Prioridade = (Impacto Ã— Severidade) / EsforÃ§o

**Impacto:** 1-10 (baixo-alto)
**Severidade:** CRITICAL=4, HIGH=3, MEDIUM=2, LOW=1
**EsforÃ§o:** horas estimadas
```

### Passo 10: Aplicar Auto-Fixes (se --auto-fix)

**CRÃTICO:** Apenas correÃ§Ãµes seguras e nÃ£o-destrutivas

**9.1. Recalcular QA Story Points**

```markdown
**SE auto-fix = true E discrepÃ¢ncia > 20%:**

1. Calcular pontos corretos usando fÃ³rmula do framework
2. Gerar backup da task atual
3. Atualizar custom field ou label com novos pontos
4. Adicionar comentÃ¡rio explicando mudanÃ§a:
   "ğŸ”§ Auto-fix: QA Story Points recalculados de [X] para [Y] pontos baseado no Framework de Testes. FÃ³rmula: [detalhes]"
5. Log da alteraÃ§Ã£o para relatÃ³rio
```

**9.2. Adicionar Labels/Tags Faltantes**

```markdown
**SE labels obrigatÃ³rias faltando:**

1. Identificar labels necessÃ¡rias:
   - Perspectiva: white-box, grey-box, black-box
   - Tipo: unit, integration, e2e, acceptance
   - Prioridade: critical, high, medium, low
2. Adicionar labels faltantes Ã s tasks
3. Comentar: "ğŸ·ï¸ Auto-fix: Labels adicionadas para melhor categorizaÃ§Ã£o"
4. Log da alteraÃ§Ã£o
```

**9.3. Criar Subtasks para Perspectivas Faltantes**

```markdown
**SE perspectiva faltando E auto-fix = true:**

1. Calcular pontos para perspectiva faltante
2. Criar subtask no epic:
   - Nome: "[Perspectiva] Testing ([X] QA points)"
   - DescriÃ§Ã£o: Template da perspectiva do framework
   - Labels: [perspectiva, testing]
   - Custom fields: QA Story Points = [X]
3. Comentar no epic: "â• Auto-fix: Subtask criada para perspectiva [X] faltante"
4. Log da criaÃ§Ã£o
```

**9.4. Atualizar Templates**

```markdown
**SE acceptance criteria incompletos:**

1. Identificar campos faltantes do template universal
2. Adicionar campos faltantes Ã  descriÃ§Ã£o da task
3. Usar template do framework como base
4. Comentar: "ğŸ“ Auto-fix: Template atualizado para conformidade com framework"
5. Log da alteraÃ§Ã£o
```

**9.5. Limites de Auto-Fix**

```markdown
**NUNCA fazer auto-fix de:**

- Deletar tasks existentes
- Modificar cÃ³digo de testes
- Alterar estimativas sem validaÃ§Ã£o se discrepÃ¢ncia < 20%
- Criar tasks sem contexto suficiente
- Modificar histÃ³rico ou comentÃ¡rios existentes

**SEMPRE:**

- Gerar backup antes de mudanÃ§as
- Log detalhado de todas alteraÃ§Ãµes
- Comentar mudanÃ§as nas tasks afetadas
- Permitir rollback se necessÃ¡rio
```

### Passo 11: Gerar RelatÃ³rio Detalhado

**10.1. Estrutura do RelatÃ³rio**

```markdown
# ğŸ“Š AnÃ¡lise de EstratÃ©gia de Teste: [Feature Name]

**Data:** [YYYY-MM-DD HH:MM]
**Feature ID:** [feature-id]
**Task Manager:** [provedor]
**Analisado por:** Sistema Onion Test Strategy Analyzer

## ğŸ“‹ Resumo Executivo

- **Score de Conformidade:** [X]% ([classificaÃ§Ã£o])
- **Total de Gaps Identificados:** [N]
  - CRITICAL: [N]
  - HIGH: [N]
  - MEDIUM: [N]
  - LOW: [N]
- **Risco de Qualidade:** [Alto/MÃ©dio/Baixo]
- **Impacto Estimado:** [X] horas

## ğŸ“Š Dados Coletados

### Task Manager Data

- Epic/Feature: [nome] ([ID])
- Status: [status]
- QA Points AtribuÃ­dos: [X] pontos
- QA Points Esperados: [Y] pontos
- Subtasks: [N] tasks
- Perspectivas Cobertas: [White/Grey/Black-box]

### Code Analysis (se deep-scan)

- Test Files: [N] arquivos
- Coverage: [X]%
- Test Types: [lista]
- CI/CD: [configurado/nÃ£o configurado]

## âœ… Conformidade com Framework

### QA Story Points Validation

- **Score:** [X]% conforme
- **DiscrepÃ¢ncias:** [lista de tasks com problemas]
- **DistribuiÃ§Ã£o:** [anÃ¡lise por perspectiva]

### Multi-Perspective Coverage

- **Score:** [X]% completo
- **White-box:** [presente/faltando] ([detalhes])
- **Grey-box:** [presente/faltando] ([detalhes])
- **Black-box:** [presente/faltando] ([detalhes])

### Template Compliance

- **Score:** [X]% conforme
- **Problemas:** [lista de nÃ£o-conformidades]

### Collaboration Patterns

- **Three Amigos:** [evidÃªncia encontrada/nÃ£o encontrada]
- **Pair Testing:** [evidÃªncia encontrada/nÃ£o encontrada]
- **Handoff Protocols:** [evidÃªncia encontrada/nÃ£o encontrada]

## ğŸ” Gap Analysis

### CRITICAL Gaps

[Para cada gap crÃ­tico:]

- **Gap:** [descriÃ§Ã£o]
- **Impacto:** [descriÃ§Ã£o do impacto]
- **Risco:** [nÃ­vel de risco]
- **AÃ§Ã£o Recomendada:** [aÃ§Ã£o especÃ­fica]
- **EsforÃ§o Estimado:** [X] horas

### HIGH Gaps

[Similar para gaps HIGH]

### MEDIUM Gaps

[Similar para gaps MEDIUM]

### LOW Gaps

[Similar para gaps LOW]

## ğŸ“ˆ Impact Assessment

### Risco de Bugs em ProduÃ§Ã£o

- **NÃ­vel:** [Alto/MÃ©dio/Baixo]
- **Fatores:** [lista de fatores de risco]

### EficiÃªncia Perdida

- **Tempo Impactado:** [X] horas
- **Custo Estimado:** [se aplicÃ¡vel]

### Qualidade Comprometida

- **Score Atual:** [X]/100
- **Score Esperado:** [Y]/100
- **Gap:** [Z] pontos

### Velocity do Time

- **Impacto:** [descriÃ§Ã£o]
- **RecomendaÃ§Ãµes:** [aÃ§Ãµes para melhorar]

## ğŸ’¡ Improvement Recommendations

### Prioridade CRITICAL

[Para cada sugestÃ£o crÃ­tica:]

1. **[TÃ­tulo da SugestÃ£o]**
   - **Problema:** [descriÃ§Ã£o]
   - **SoluÃ§Ã£o:** [aÃ§Ã£o especÃ­fica]
   - **Impacto:** [benefÃ­cio esperado]
   - **EsforÃ§o:** [X] horas
   - **ROI:** [se aplicÃ¡vel]

### Prioridade HIGH

[Similar para HIGH]

### Prioridade MEDIUM

[Similar para MEDIUM]

### Prioridade LOW

[Similar para LOW]

## ğŸ“Š Metrics Tracking

### Current vs Target

| MÃ©trica           | Atual | Target | Status     | Gap  |
| ----------------- | ----- | ------ | ---------- | ---- |
| Unit Coverage     | [X]%  | >80%   | [âœ…/âš ï¸/âŒ] | [Y]% |
| Integration Pass  | [X]%  | >95%   | [âœ…/âš ï¸/âŒ] | [Y]% |
| E2E Flakiness     | [X]%  | <3%    | [âœ…/âš ï¸/âŒ] | [Y]% |
| QA Estimation Acc | [X]%  | >85%   | [âœ…/âš ï¸/âŒ] | [Y]% |

## ğŸ”§ Auto-Fixes Aplicados (se --auto-fix)

[Para cada auto-fix:]

- **Task:** [ID] - [nome]
- **AÃ§Ã£o:** [descriÃ§Ã£o da correÃ§Ã£o]
- **Antes:** [estado anterior]
- **Depois:** [estado apÃ³s correÃ§Ã£o]
- **Timestamp:** [data/hora]

## ğŸ“‹ Action Items

[Lista priorizada de aÃ§Ãµes:]

- [ ] [AÃ§Ã£o 1] - [responsÃ¡vel] - [prazo]
- [ ] [AÃ§Ã£o 2] - [responsÃ¡vel] - [prazo]

## ğŸ”— ReferÃªncias

- Framework: `docs/knowbase/frameworks/framework_testes.md`
- Tasks Analisadas: [links para tasks]
- RelatÃ³rios Relacionados: [se houver]

---

**Gerado por:** Sistema Onion v3.0
**VersÃ£o do Analyzer:** 3.0.0
```

**10.2. Salvar RelatÃ³rio**

```bash
# Criar diretÃ³rio se nÃ£o existir
mkdir -p reports/test-strategy-analysis

# Salvar relatÃ³rio
write reports/test-strategy-analysis/analysis-[feature-id]-[YYYYMMDD-HHMM].md
```

**SE export-report = true:**

- Gerar tambÃ©m versÃ£o JSON estruturada
- Gerar versÃ£o executiva (resumo de 1 pÃ¡gina)
- Incluir grÃ¡ficos se possÃ­vel (mÃ©tricas visuais)

### Passo 12: Apresentar Resultado Final

## ğŸ“¤ Output Esperado

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” ANÃLISE DE ESTRATÃ‰GIA DE TESTE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Feature: [feature-id] - [nome]
ğŸ“Š Task Manager: [provedor] (inferido do .env: TASK_MANAGER_PROVIDER=[valor])

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ DATA COLLECTION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Conectado ao [task-manager]
âœ“ Epic encontrado: "[nome]" ([ID])
âœ“ Coletadas [N] tasks relacionadas em [X] sprints
[SE deep-scan:] âœ“ Analisado codebase e cobertura de testes
[SE deep-scan:] âœ“ Coletadas mÃ©tricas de execuÃ§Ã£o do CI/CD

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… FRAMEWORK COMPLIANCE ANALYSIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸ QA Story Points: [X]% conforme
  â””â”€â”€ [N] tasks usando cÃ¡lculo incorreto
  â””â”€â”€ DiscrepÃ¢ncia mÃ©dia: [Â±X] pontos

âœ… Multi-Perspective: [X]% cobertura
  â””â”€â”€ White-box: [presente/faltando]
  â””â”€â”€ Grey-box: [presente/faltando]
  â””â”€â”€ Black-box: [presente/faltando]

âŒ Test Metrics: [N] thresholds crÃ­ticos nÃ£o atingidos
  â””â”€â”€ Coverage: [X]% (target: >80%)
  â””â”€â”€ Pass Rate: [X]% (target: >95%)
  â””â”€â”€ [outras mÃ©tricas]

âš ï¸ Collaboration: Conformidade parcial
  â””â”€â”€ Three Amigos: [evidÃªncia encontrada/nÃ£o encontrada]
  â””â”€â”€ Pair Testing: [evidÃªncia encontrada/nÃ£o encontrada]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” GAP ANALYSIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”´ CRITICAL ([N] issues):
  â””â”€â”€ [Gap 1]: [descriÃ§Ã£o breve]
  â””â”€â”€ [Gap 2]: [descriÃ§Ã£o breve]

ğŸŸ¡ HIGH ([N] issues):
  â””â”€â”€ [Gap 1]: [descriÃ§Ã£o breve]
  â””â”€â”€ [Gap 2]: [descriÃ§Ã£o breve]
  â””â”€â”€ [Gap 3]: [descriÃ§Ã£o breve]

ğŸŸ¢ MEDIUM ([N] issues):
  â””â”€â”€ [Gap 1]: [descriÃ§Ã£o breve]
  â””â”€â”€ [Gap 2]: [descriÃ§Ã£o breve]

ğŸ”µ LOW ([N] issues):
  â””â”€â”€ [Gap 1]: [descriÃ§Ã£o breve]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š IMPACT ASSESSMENT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Risk Level: [ALTO/MÃ‰DIO/BAIXO]
Estimated Bug Leakage: [Â±X]% increase
Team Velocity Impact: [Â±X]%
Technical Debt: [X] hours
Quality Score: [X]/100 ([classificaÃ§Ã£o])

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ IMPROVEMENT RECOMMENDATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”´ CRITICAL - Fix Immediately:

1. [TÃ­tulo da SugestÃ£o]
   â””â”€â”€ EsforÃ§o: [X] horas | Impacto: [descriÃ§Ã£o]
   â””â”€â”€ Foco em: [Ã¡reas especÃ­ficas]
   [SE auto-fix disponÃ­vel:] â””â”€â”€ Auto-fix disponÃ­vel: --auto-fix

2. [TÃ­tulo da SugestÃ£o]
   â””â”€â”€ EsforÃ§o: [X] horas | Impacto: [descriÃ§Ã£o]

ğŸŸ¡ HIGH - Next Sprint:

3. [TÃ­tulo da SugestÃ£o]
   â””â”€â”€ EsforÃ§o: [X] horas | Impacto: [descriÃ§Ã£o]
   [SE auto-fix disponÃ­vel:] â””â”€â”€ Auto-fix disponÃ­vel: --auto-fix

4. [TÃ­tulo da SugestÃ£o]
   â””â”€â”€ EsforÃ§o: [X] horas | Impacto: [descriÃ§Ã£o]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š METRICS TRACKING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Current vs Target:

- Unit Coverage: [X]% â†’ 80% (target) [gap: Â±Y%]
- Integration Pass: [X]% â†’ 95% (target) [gap: Â±Y%]
- E2E Flakiness: [X]% â†’ <3% (target) [gap: Â±Y%]
- QA Estimation Accuracy: [X]% â†’ 85% (target) [gap: Â±Y%]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ GENERATED REPORTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[SE export-report:]
âœ“ Detailed analysis: ./reports/test-strategy-analysis/analysis-[feature-id]-[date].md
âœ“ Executive summary: ./reports/test-strategy-analysis/exec-summary-[feature-id].md
âœ“ Action items JSON: ./reports/test-strategy-analysis/actions-[feature-id].json

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”§ AUTO-FIXES APPLIED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[SE auto-fix aplicado:]
âœ“ [N] QA Story Points recalculados
âœ“ [N] labels adicionadas
âœ“ [N] subtasks criadas para perspectivas faltantes
âœ“ [N] templates atualizados

ğŸ“‹ Log completo: Ver relatÃ³rio detalhado

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ¨ AnÃ¡lise completa! [N] gaps identificados, [M] melhorias sugeridas.

ğŸ’¡ PrÃ³ximos Passos:
1. Revisar gaps crÃ­ticos e altos
2. Aplicar melhorias prioritÃ¡rias
3. [SE auto-fix nÃ£o usado:] Executar com --auto-fix para correÃ§Ãµes automÃ¡ticas
4. Monitorar mÃ©tricas ao longo do tempo

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## ğŸ“‹ Exemplos de Uso

### Exemplo 1: AnÃ¡lise BÃ¡sica (Provedor Inferido do .env)

```bash
/test-strategy/analyze PROJ-123
```

**Output esperado:**

- Provedor detectado automaticamente do `TASK_MANAGER_PROVIDER` no `.env`
- AnÃ¡lise de conformidade bÃ¡sica
- IdentificaÃ§Ã£o de gaps principais
- SugestÃµes priorizadas
- RelatÃ³rio em console

### Exemplo 2: AnÃ¡lise com Provedor ExplÃ­cito

```bash
/test-strategy/analyze CU-456 --task-manager clickup
```

**Output esperado:**

- Usa provedor especificado (ignora .env)
- Ãštil quando precisa analisar task de outro provedor
- AnÃ¡lise completa

### Exemplo 3: AnÃ¡lise Profunda com Auto-Fix (Provedor Inferido)

```bash
/test-strategy/analyze TICKET-101 --deep-scan --auto-fix
```

**Output esperado:**

- Provedor inferido do `.env` ou formato do ID
- AnÃ¡lise completa incluindo cÃ³digo
- CorreÃ§Ãµes automÃ¡ticas aplicadas
- RelatÃ³rio detalhado
- Log de todas alteraÃ§Ãµes

### Exemplo 4: AnÃ¡lise Completa com RelatÃ³rio

```bash
/test-strategy/analyze FEATURE-789 --deep-scan --export-report --auto-fix
```

**Output esperado:**

- Provedor detectado automaticamente
- Todas funcionalidades ativadas
- AnÃ¡lise mais completa possÃ­vel
- CorreÃ§Ãµes aplicadas
- RelatÃ³rios em mÃºltiplos formatos (markdown, JSON, executivo)

## âš ï¸ ValidaÃ§Ãµes e Regras

### ValidaÃ§Ãµes ObrigatÃ³rias

1. **Framework deve existir:**

   ```markdown
   SE framework_testes.md nÃ£o encontrado:
   âŒ ERRO: Framework nÃ£o encontrado
   ğŸ’¡ Verifique: docs/knowbase/frameworks/framework_testes.md
   ```

2. **Feature ID nÃ£o vazio:**

   ```markdown
   SE feature-id vazio:
   âŒ ERRO: Feature ID Ã© obrigatÃ³rio
   ```

3. **Task Manager detectado e acessÃ­vel:**

   ```markdown
   SE nÃ£o conseguir detectar provedor:
   âŒ ERRO: NÃ£o foi possÃ­vel detectar task manager
   ğŸ’¡ Configure TASK_MANAGER_PROVIDER no .env ou forneÃ§a --task-manager

   SE nÃ£o conseguir conectar ao task manager detectado:
   âŒ ERRO: NÃ£o foi possÃ­vel conectar ao [provedor]
   ğŸ’¡ Verifique configuraÃ§Ã£o em .env (API tokens, workspace IDs, etc)
   ```

4. **Epic/Feature encontrado:**
   ```markdown
   SE epic nÃ£o encontrado no task manager:
   âŒ ERRO: Feature [feature-id] nÃ£o encontrada
   ğŸ’¡ Verifique se o ID estÃ¡ correto
   ```

### Regras de NegÃ³cio

1. **AnÃ¡lise sempre baseada no framework:** Todas verificaÃ§Ãµes devem referenciar seÃ§Ãµes especÃ­ficas do framework
2. **Auto-fix apenas seguro:** Nunca aplicar mudanÃ§as destrutivas automaticamente
3. **PriorizaÃ§Ã£o inteligente:** SugestÃµes ordenadas por impacto/effort ratio
4. **RelatÃ³rios acionÃ¡veis:** Todas sugestÃµes devem incluir aÃ§Ãµes especÃ­ficas e estimativas
5. **Preservar histÃ³rico:** Nunca deletar ou modificar dados histÃ³ricos

## ğŸ”— ReferÃªncias

- **Framework:** `docs/knowbase/frameworks/framework_testes.md`
- **Comando relacionado:** `/validate/test-strategy/create`
- **Task Manager:** `${CLAUDE_PLUGIN_ROOT}/reference/utils/task-manager/`
- **Agentes relacionados:** @test-engineer, @test-planner

## âš ï¸ Notas Importantes

- **Framework Ã© obrigatÃ³rio:** Comando falha se `framework_testes.md` nÃ£o existir
- **AnÃ¡lise baseada em evidÃªncias:** Todas conclusÃµes devem ser baseadas em dados coletados
- **Auto-fix conservador:** Apenas correÃ§Ãµes seguras e nÃ£o-destrutivas
- **RelatÃ³rios detalhados:** Use `--export-report` para anÃ¡lises formais
- **Deep-scan opcional:** Use `--deep-scan` para anÃ¡lise mais completa (mais lento)
- **IntegraÃ§Ã£o flexÃ­vel:** Funciona com mÃºltiplos task managers ou modo offline
- **DetecÃ§Ã£o automÃ¡tica:** Provedor Ã© inferido automaticamente do `.env` (TASK_MANAGER_PROVIDER), com fallback para formato do feature-id

---

**VersÃ£o:** 3.0.0  
**Ãšltima atualizaÃ§Ã£o:** 2025-12-03  
**Mantido por:** Sistema Onion
